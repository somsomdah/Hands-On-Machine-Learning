{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.load(\"datasets/X_train.npy\",allow_pickle=True)\n",
    "X_test=np.load(\"datasets/X_test.npy\",allow_pickle=True)\n",
    "y_train=np.load(\"datasets/y_train.npy\",allow_pickle=True)\n",
    "y_test=np.load(\"datasets/y_test.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit=X_train[35]\n",
    "y_train[35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 다중 분류 (multiclass_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이진 분류기를 활용하는 방법\n",
    "- 일대다 전략(one-versus-all,one_versus-the-rest,OvA) : 클래스 갯수만큼 이진분류기를 훈련시킨다\n",
    "    - 대부분의 분류 알고리즘에서 OvA 선호\n",
    "- 일대일 전략(one-versus-one,OvO) : 클래스의 조합마다 이진분류기를 훈련시킨다. \n",
    "    - 각 분류기의 훈련에 전체 훈련세트 중 두 클래스만 필요\n",
    "    - SVM은 작은 훈련세트에서 많은 분류기를 훈련시키는 쪽이 빠르기 때문에 OvO 선호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf=SGDClassifier(max_iter=5,random_state=43)\n",
    "sgd_clf.fit(X_train,y_train)\n",
    "\n",
    "sgd_digit_prediction = sgd_clf.predict([some_digit])\n",
    "sgd_digit_scores = sgd_clf.decision_function([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n",
      "[[-289196.97653428 -395691.23756907 -248716.80073497 -486384.05171083\n",
      "  -349599.06445628  366548.57730945  -45460.95698637 -823651.48557537\n",
      "  -521603.05192652 -785507.65424711]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(sgd_digit_prediction)\n",
    "print(sgd_digit_scores)\n",
    "print(np.argmax(sgd_digit_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "ovo_clf = OneVsOneClassifier(SGDClassifier(max_iter=5, random_state=42))\n",
    "ovo_clf.fit(X_train, y_train)\n",
    "\n",
    "ovo_prediction = ovo_clf.predict([some_digit])\n",
    "ovo_estimators = ovo_clf.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "print(ovo_prediction)\n",
    "print(len(ovo_estimators)) # 9*10/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중 분류기를 활용하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "forest_clf.fit(X_train, y_train)\n",
    "\n",
    "forest_prediction=forest_clf.predict([some_digit])\n",
    "forest_probability=forest_clf.predict_proba([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(forest_prediction)\n",
    "print(forest_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.91021796, 0.90734537, 0.90918638])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스케일링\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "\n",
    "cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5 오류 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\DASOM\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5737    3   26    7   12   44   47    8   37    2]\n",
      " [   1 6474   41   28    6   44   10   12  113   13]\n",
      " [  62   40 5299  102   83   25  103   63  162   19]\n",
      " [  51   38  134 5337    4  248   42   59  126   92]\n",
      " [  21   28   36    8 5369    8   56   30   90  196]\n",
      " [  72   36   32  191   73 4609  118   27  169   94]\n",
      " [  32   23   43    2   39   91 5636    6   44    2]\n",
      " [  24   22   65   29   50    8    8 5803   16  240]\n",
      " [  58  154   74  171   16  160   56   24 4995  143]\n",
      " [  38   32   28   89  169   38    2  204   73 5276]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(conf_mx)\n",
    "\n",
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 예측의 오류를 가시화 해주는 그래프\n",
    "\n",
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums\n",
    "\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5 다중 레이블 분류 (multilabel classification)\n",
    "- 하나의 샘플에 대하여 여러개의 이진 레이블을 출력하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "y_train_large = (y_train >= 7) # 7보다 큰 숫자를 분류하는 레이블\n",
    "y_train_odd = (y_train % 2 == 1) # 짝수와 홀수를 분류하는 레이블\n",
    "y_multilabel = np.c_[y_train_large, y_train_odd] # 두개의 열벡터를 행방향으로 붙임\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간 너무 많이 소요\n",
    "#y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3, n_jobs=-1)\n",
    "#f1_score(y_multilabel, y_train_knn_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 다중 출력 분류 (multioutput-multiclass classification)\n",
    "- 하나의 샘플에 대하여 여러개의 다중 레이블을 출력하는 것\n",
    "- 이미지에서 노이즈 제거 : 픽셀당 하나의 레이블을 가지며(여러개의 레이블) 레이블 값이 1~255이다(다중 출력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 데이터에 노이즈 입히기\n",
    "\n",
    "train_noise = np.random.randint(0, 100, (len(X_train), 784))\n",
    "test_noise = np.random.randint(0, 100, (len(X_test), 784))\n",
    "\n",
    "X_train_mod = X_train + train_noise\n",
    "X_test_mod = X_test + test_noise\n",
    "\n",
    "y_train_mod = X_train\n",
    "y_test_mod = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_index = 5500\n",
    "plt.subplot(121); plot_digit(X_test_mod[some_index]) # 입력 예시\n",
    "plt.subplot(122); plot_digit(y_test_mod[some_index]) # 출력 예시\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf.fit(X_train_mod, y_train_mod)\n",
    "clean_digit = knn_clf.predict([X_test_mod[some_index]])\n",
    "plot_digit(clean_digit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
