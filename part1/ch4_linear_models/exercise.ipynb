{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 수백만개의 특성을 가진 훈련 세트에는 어떤 선형 회귀 알고리즘을 사용할 수 있을까?\n",
    "> ~~linear regression : 빠르니까?~~ __확률적 경사 하강법 또는 미니배치 경사 하강법. 정규방정식은 계산 복잡도가 특성 개수에 따라 매우 빠르게 변하기 때문에 사용할 수 없다. 정규방정식의 계산복잡도는 특성수의 3승 배로 증가하고, 샘플 수에는 선형적으로 증가한다. 따라서 특성 수가 매우 많아지면 정규방정식을 이용한 방법은 많이 느려짐.__\n",
    "2. 훈련 세트에 있는 특성들이 각기 아주 다른 스케일을 가지고 있을 때. 이런 데이터에 잘 작동하지 않는 알고리즘은?\n",
    "> __정규방정식은 스케일링 없이도 잘 작동한다. 경사하강법은 스케일링이 없으면 수렴하는 데에 오래 걸림. 규제가 있는 모델은 특성 스케일이 다르면 지역 최적점에 수렴할 수 있음. 규제는 가중치의 크기를 제한하기 때문에 특성값이 작으면 무시될 수 있음.__\n",
    "3. 경사 하강법으로 로지스틱 회귀 모델을 훈련 시킬 때 지역 최솟값에 갇힐 가능성이 있을까?\n",
    "> 비용함수가 볼록하기 때문에 그럴 일 없음\n",
    "4. 충분히 오랫동안 실행하면 모든 경사 하강법 알고리즘이 같은 모델을 만들어낼까?\n",
    "> 아니다. 수렴하지 않을 수도 있기 때문에. __학습률을 점진적을 감소지키지 않으면 sgd나 미니배치 gd는 수렴하지 않을 수도 있다.__\n",
    "5. 배치 경사 하강법을 사용하고 에포크마아 검증 오차를 그래프로 나타내었다. 검증 오차가 상승하고 있다면?\n",
    "> overfitting, ~~규제가 있는 모델을 사용하여 해결~~ 조기종료. __학습률을 잘못 조절해서 비용함수 값이 발산 할 수 있음. 그게 아니더라도 과대적합의 가능성이 잆음__\n",
    "6. 검증 오차가 상승하면 미니배치 경사 하강법을 즉시 중 단하는 것이 좋은가?\n",
    "> ~~글쎄~~ __무작위성으로 인해 sgd나 미니배치gd는 매 훈련마나 학습 진전을 보장하지는 못함. 따라서 정기적으로 모델을 저장하고(일정 시간 간격으로 가중치 저장)오래동안 진전이 없을 때 저장된 것들 중 가장 좋은모델 사용하면 됨__\n",
    "\n",
    "7. 어떤 경사 하강법이 가장 빠르게 최적의 솔루션에 도달할까? 실제로 수렴하는 것은?\n",
    "> ~~미니배치?~~ __sgd가 가장 빠르게 전역 최소값 근처에 도달(하나의 샘플마다 움직이므로) 하지만 학습률을 감소시키지 않으면 수렴하지 않고 최적점 주변을 맴돌 것이다. learning rate decay가 없고, 시간이 충분하다면 실제로는 gd가 최적점에 빨리 도달할 것__\n",
    "8. 다항 회귀를 사용했을 때, 훈련 오차와 검증 오차 사이에 간격이 클 때\n",
    "> overfitting 발생 --> 규제, ~~조기종료~~, __다항 차수 낮추기(자유도 줄임), 훈련 세트의 크기를 증가시킴__\n",
    "\n",
    "9. 릿지 회귀를 사용했을 때 훈련 오차와 검증 오차가 비슷하고 둘 다 높았다. 편향/분산 중에 무엇이 문제인가, 하이퍼 파라미터 $\\alpha$를 어떻게 조절해야 하나?\n",
    "> underfitting, 편향이 높다, 알파를...알파가 뭐지? __알파는 규제를 조절하는 파라미터, 1에 가까울수록 규제가 커짐. 편향이 높으므로 알파를 감소시켜 규제를 완화해야 함__ \n",
    "\n",
    "10. 다음과 같이 사용해야하는 이유는?\n",
    "    - 선형 회귀 대신 릿지 회귀\n",
    "> overfitting 방지. __규제가 없는 모델보다 성능이 좋아서__\n",
    "    - 릿지 회귀 대신 라쏘 회귀\n",
    "> 특성제거. __라쏘 회귀는 가장 중요한 가중치를 제외하고 모든 가중치를 0으로 만드는 희소한 모델을 만든다. 자동으로 특성 선택을 해주므로 몇개의 특성만 유용하다고 판단될 때 사용해주면 됨.__\n",
    "    - 라쏘 회귀 대신 엘라스틱넷\n",
    "> ~~몰라~~ __몇개의 특성이 연관되어 있거나 훈련 샘플보다 특성 수가 많을 때 라쏘는 불규칙하게 행동함. 따라서 엘라스틱넷이 라쏘보다 선호됨. 불규칙한 행동이 없는 라쏘를 원하면 l1_ratio를 1에 가깝게 설정하면 됨__ >>>>>>> 무슨 말인지 모르겠음.... 왜 ㅣ1_ratio를 1에 가깝게 하는지..?\n",
    "\n",
    "11. 사진을 낮과 밤, 실내와 실외로 분류하려고 할 때. \n",
    "> 두개의 로지스틱 회귀 분류 __서로 배타적이인 클래스가 아니기 때문에__\n",
    "\n",
    "12. 조기종료를 사용한 배치 경사 하강법으로 소프트맥스를 구현해봐라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
